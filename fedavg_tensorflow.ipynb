{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fedavg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTI2lBiGYdct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "caf7a295-2b8f-429f-fea3-2176ea9339d7"
      },
      "source": [
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXm4L2WMYvYW"
      },
      "source": [
        "def build_dict(y_train, y_test):\n",
        "    train_dict, test_dict = {}, {}\n",
        "    \n",
        "    for label in range(10):\n",
        "      train_dict[label] = np.argwhere(label==y_train).reshape(-1)\n",
        "      test_dict[label] = np.argwhere(label==y_test).reshape(-1)\n",
        "\n",
        "    return train_dict, test_dict\n",
        "\n",
        "def create_clients(x_train, y_train, x_test, y_test, num_clients):\n",
        "\n",
        "    \"\"\"\n",
        "      Builds a list of Non-IID clients for the demo\n",
        "        - Generates dictionaries of train and test dataset indices according to labels\n",
        "        - Based on dictionaries, pick two random labels with replacement\n",
        "        - Pick 100 random samples from the picked labels for train and test set\n",
        "    \"\"\"\n",
        "    # Client Data Size\n",
        "    client_size = x_train.shape[0] // num_clients\n",
        "    shard_size = client_size // 2\n",
        "\n",
        "    # Build Dictionaries\n",
        "    train_dict, test_dict = build_dict(y_train, y_test)\n",
        "\n",
        "    clients = []\n",
        "    for i in range(num_clients):\n",
        "        if (i % 20 == 0): print(\"Generating %d-th Clients ...\" % (i+20))\n",
        "        labels = np.random.choice(10, 2)\n",
        "\n",
        "        train_ind = [np.random.choice(train_dict[l], shard_size) for l in labels]\n",
        "        train_ind = [i for l in train_ind for i in l]\n",
        "        train_inputs = tf.cast(tf.gather(x_train, train_ind), tf.float32)\n",
        "        train_labels = tf.cast(tf.gather(y_train, train_ind), tf.uint8)\n",
        "\n",
        "        test_ind = [np.random.choice(test_dict[l], shard_size) for l in labels]\n",
        "        test_ind = [i for l in test_ind for i in l]\n",
        "        test_inputs = tf.cast(tf.gather(x_test, test_ind), tf.float32)\n",
        "        test_labels = tf.cast(tf.gather(y_test, test_ind), tf.uint8)\n",
        "\n",
        "        clients.append(Client(train_inputs, train_labels, test_inputs, test_labels))\n",
        "    \n",
        "    return clients\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0RNBraeY9Zd"
      },
      "source": [
        "class Client(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, x_train, y_train, x_test, y_test):\n",
        "        super(Client, self).__init__()\n",
        "        \n",
        "        # Inputs and Labels\n",
        "        self.num_samples = x_train.shape[0]\n",
        "\n",
        "        self.train_inputs, self.train_labels = x_train, y_train\n",
        "        self.test_inputs, self.test_labels = x_test, y_test\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.hidden_size = 200\n",
        "        self.num_classes = 10\n",
        "        self.num_epochs = 10\n",
        "        self.batch_size = self.num_samples // 30\n",
        "\n",
        "        # Initializer\n",
        "        init = tf.keras.initializers.RandomNormal(stddev=0.1)\n",
        "\n",
        "        # Layers (Need to be built prior to call)\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(self.hidden_size, activation='relu',\n",
        "                                  kernel_initializer=init, bias_initializer=init),\n",
        "            tf.keras.layers.Dense(self.num_classes, activation='softmax',\n",
        "                                  kernel_initializer=init, bias_initializer=init)\n",
        "        ])\n",
        "        self.model.build((None, 784))\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
        "\n",
        "        # Loss\n",
        "        self.loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.model(inputs)\n",
        "\n",
        "    def loss(self, logits, labels):\n",
        "        l = self.loss_function(labels, logits)\n",
        "        return tf.reduce_mean(l)\n",
        "\n",
        "    def train(self, weights):\n",
        "        self.model.set_weights(weights)\n",
        "        for _ in range(self.num_epochs):\n",
        "            shuffled = tf.random.shuffle(range(self.num_samples))\n",
        "            inputs = tf.gather(self.train_inputs, shuffled)\n",
        "            labels = tf.gather(self.train_labels, shuffled)\n",
        "            for i in range(self.num_samples//self.batch_size):\n",
        "                start, end = i*self.batch_size, (i+1)*self.batch_size\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    l = self.loss(self.call(inputs[start:end]), labels[start:end])\n",
        "                \n",
        "                g = tape.gradient(l, self.trainable_variables)\n",
        "                self.optimizer.apply_gradients(zip(g, self.trainable_variables))\n",
        "\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def test(self):\n",
        "        logits = self.call(self.test_inputs)\n",
        "        preds = np.argmax(logits, axis=1)\n",
        "        num_correct = np.sum(self.test_labels == preds)\n",
        "        return num_correct\n",
        "\n",
        "class Server:\n",
        "\n",
        "    def __init__(self, clients):     \n",
        "        # Clients\n",
        "        self.clients = clients\n",
        "\n",
        "        self.num_clients = len(clients)\n",
        "        self.total_samples = sum(c.num_samples for c in self.clients)\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.num_rounds = 25\n",
        "        self.num_classes = self.clients[0].num_classes\n",
        "        self.hidden_size = self.clients[0].hidden_size\n",
        "\n",
        "        self.C_fixed = False\n",
        "\n",
        "        # Initializer\n",
        "        init = tf.keras.initializers.RandomNormal(stddev=0.1)\n",
        "\n",
        "        # Layers (Needs to be built before call)\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(self.hidden_size, activation='relu',\n",
        "                                  kernel_initializer=init, bias_initializer=init),\n",
        "            tf.keras.layers.Dense(self.num_classes, activation='softmax',\n",
        "                                  kernel_initializer=init, bias_initializer=init)\n",
        "        ])\n",
        "        self.model.build((None, 784))\n",
        "    \n",
        "    def update(self):\n",
        "        for t in range(self.num_rounds):\n",
        "            # Create Random Sample of Clients\n",
        "            if self.C_fixed: \n",
        "                p = 1\n",
        "            else:\n",
        "                p = min(1, 1.1 * random.random())\n",
        "\n",
        "            m = max(1, int(self.num_clients * p))\n",
        "            sample = np.random.choice(self.clients, m)\n",
        "            print('ROUND %d / %d NUM SAMPLES : %d' % (t+1, self.num_rounds, m))\n",
        "            \n",
        "            # Update Client Weights (Train) in Sample\n",
        "            for client in sample:\n",
        "                weights = client.train(self.model.get_weights())\n",
        "                client.model.set_weights(weights)\n",
        "\n",
        "            # Update Server Weights\n",
        "            server_weights = self.model.get_weights()\n",
        "            for client in self.clients:\n",
        "                pk = client.num_samples / self.total_samples\n",
        "\n",
        "                for sw, w in zip(server_weights, client.model.get_weights()):\n",
        "                    sw = sw + w * pk\n",
        "\n",
        "            self.model.set_weights(server_weights)\n",
        "\n",
        "            # Testing\n",
        "            acc = self.test()\n",
        "            print('ROUND %d / %d UPDATE ACCURACY : %.2f %%' % (t+1, self.num_rounds, acc * 100))\n",
        "            \n",
        "        return acc\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.model(inputs)\n",
        "    \n",
        "    def test(self):\n",
        "        correct, samples = 0, 0\n",
        "        for c in self.clients:\n",
        "            samples += c.test_inputs.shape[0]\n",
        "            correct += c.test()\n",
        "        return correct / samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzSbG6sq-_hE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "b93706ce-9b62-4048-fd42-fda52a44e005"
      },
      "source": [
        "# Load and Normalize Data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0 \n",
        "\n",
        "# Create Dictionaries for Non-IID Data Generation\n",
        "train_dict, test_dict = build_dict(y_train, y_test)\n",
        "\n",
        "# Create List of Clients\n",
        "clients = create_clients(x_train, y_train, x_test, y_test, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating 20-th Clients ...\n",
            "Generating 40-th Clients ...\n",
            "Generating 60-th Clients ...\n",
            "Generating 80-th Clients ...\n",
            "Generating 100-th Clients ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9KTl1D6nRPh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "0d9e024e-57cd-4031-fd20-b611d9b848f0"
      },
      "source": [
        "def build_model(weights):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(200),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "    model.build((None, 784))\n",
        "    model.set_weights(weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_weights():\n",
        "    W1 = tf.random.normal([784, 200], stddev=0.1)\n",
        "    b1 = tf.random.normal([200], stddev=0.1)\n",
        "    W2 = tf.random.normal([200, 10], stddev=0.1)\n",
        "    b2 = tf.random.normal([10], stddev=0.1)\n",
        "\n",
        "    return [W1, b1, W2, b2]\n",
        "\n",
        "def loss_surface_demo():\n",
        "    weight1 = build_weights()\n",
        "    weight2 = build_weights()\n",
        "\n",
        "    theta = np.linspace(-.2, 1.2, 50)\n",
        "\n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    r = np.random.choice(60000, 1200)\n",
        "    ind1 = r[:600]\n",
        "    ind2 = r[600:]\n",
        "\n",
        "    # Common Init\n",
        "    tf.random.set_seed(1)\n",
        "    print(\"***** Common Initialization *****\")\n",
        "    model1 = build_model(weight1)\n",
        "    model2 = build_model(weight1)\n",
        "\n",
        "    model1.compile(optimizer=opt, loss=loss_function)\n",
        "    model2.compile(optimizer=opt, loss=loss_function)\n",
        "\n",
        "    model1.fit(x_train[ind1], y_train[ind1], batch_size=50, epochs=20, verbose=0)\n",
        "    model2.fit(x_train[ind2], y_train[ind2], batch_size=50, epochs=20, verbose=0)\n",
        "\n",
        "    common = []\n",
        "    for t in theta:\n",
        "        w1 = [t * w for w in model1.get_weights()]\n",
        "        w2 = [(1-t) * w for w in model2.get_weights()]\n",
        "     \n",
        "        weights = [w_1 + w_2 for w_1, w_2 in zip(w1, w2)]\n",
        "        model = build_model(weights)\n",
        "\n",
        "        logits = model(x_train)\n",
        "        loss = loss_function(y_train, logits)\n",
        "        common.append(loss)    \n",
        "    \n",
        "    # Different Init\n",
        "    tf.random.set_seed(None)\n",
        "    print(\"***** Independent Initialization *****\")\n",
        "    model1 = build_model(weight1)\n",
        "    model2 = build_model(weight2)\n",
        "\n",
        "    model1.compile(optimizer=opt, loss=loss_function)\n",
        "    model2.compile(optimizer=opt, loss=loss_function)\n",
        "\n",
        "    model1.fit(x_train[ind1], y_train[ind1], batch_size=50, epochs=20, verbose=0)\n",
        "    model2.fit(x_train[ind2], y_train[ind2], batch_size=50, epochs=20, verbose=0)\n",
        "\n",
        "    diff = []\n",
        "    for t in theta:\n",
        "        w1 = [t * w for w in model1.get_weights()]\n",
        "        w2 = [(1-t) * w for w in model1.get_weights()]\n",
        "        \n",
        "        weights = [w_1 + w_2 for w_1, w_2 in zip(w1, w2)]\n",
        "        model = build_model(weights)\n",
        "\n",
        "        logits = model(x_train)\n",
        "        loss = loss_function(y_train, logits)\n",
        "        diff.append(loss)\n",
        "    \n",
        "    # Plot\n",
        "    plt.figure(1)\n",
        "    plt.plot(theta, common, 'r.-', label='Common Initialization')\n",
        "    plt.plot(theta, diff, 'b.-', label='Independent Intialization')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "loss_surface_demo()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Common Initialization *****\n",
            "***** Independent Initialization *****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU1fnH8c+TEAgV3AAVRAWsCkJC\ngBCJEYiiqKjBBSsULVErYq1L/RV3WVyKdalbrRaw4oJKRUW0alUkIhDFgGFRUFyCZVFBkFplCXB+\nf5xsQJYJmZk7k3zfr1deM7lz595nJsmTM+ee8xxzziEiIrErIegARESkekrUIiIxTolaRCTGKVGL\niMQ4JWoRkRjXKBIHbdmypWvXrl0kDi0iUi/Nnz9/nXOuVWWPRSRRt2vXjoKCgkgcWkSkXjKzFVU9\npq4PEZEYp0QtIhLjlKhFRGKcErWISIxTohYRiXFK1CIiMS5xzJgxYT/o+PHjxwwfPrzWz8vPh6ef\nhkaN4JBDwr89GucI8tz1/fXpvdW54/UcoRg7duyaMWPGjK/ssYiMo94T+fnQpw9s2wYJCZCaCvvs\nAxs3wqJFsGNH3bZD+I4Vi+eu769P763OHQ/ncA6Sk2HGDMjMDF9+jJmuj7w82L7d39+xw79w8Lc7\ndtR9eziPFYvnru+vT++tzh0P53AOtm71+SysnHNh/+rRo4errblznWva1LnERH87d254t0fjHEGe\nu76/Pr23One8niNUQIGrIqeai8AKL+np6W5PppDn5/v/RNnZO39sCNf2aJwjyHPX99en91bnjtdz\nhMLM5jvn0it9LJYStYhIQ1Vdoo6ZPmoREamcErWISIxTohYRiXFK1CIiMU6JWkQkxilRi4jEuJAS\ntZldZWZLzOxjM7s60kGJiEi5GhO1mXUBLgEygK7A6Wb2y0gHJiIiXigt6k7AB865n51z24B3gbMj\nG5aIiJQKJVEvAXqbWQsz+wUwANitiJ+ZDTezAjMrWLt2bbjjFBFpsGpM1M65pcCfgTeBN4BCYHsl\n+413zqU759JbtWoV9kBFRBqqkC4mOucec871cM71ATYAn0U2LBERKRXSwgFmdoBz7jszOxTfP90r\nsmGJiEipUFd4ecHMWgDFwOXOuR8iGJOIiFQQUqJ2zvWOdCAiIlI5zUwUEYlxStQiIjFOiVpEJMYp\nUYuIxDglahGRGKdELSIS45SoRURinBK1iEiMU6IWEYlxStQiIjFOiVpEJMYpUYuIxDglahGRGKdE\nLSIS45SoRURinBK1iEiMU6IWEYlxStQiIjEupERtZn8ws4/NbImZPWtmyZEOTEREvBoTtZkdDFwJ\npDvnugCJwOCIRJOfD+PG+dtIbI/WOUREwijUVcgbAU3NrBj4BbA67JHk50OfPrB9OyQmwllnQevW\nsGYNvPRS3bdD6M855xw4+GC//fnny7cPGwbt28OqVTBxImzbBo0bw3PPQU4OJCT415GXB9nZkJkZ\n9rdJRBoec87VvJPZVcAdwCbgTefc0Or2T09PdwUFBbWLZNw4uPHG8u+Tk/3X5s3+q67bIfTnNG4M\nSUmwdSsUF4cWf9Om0KYNFBXBjh3+uDNmKFmLSEjMbL5zLr2yx0Lp+tgPGAi0B9oAe5nZ+ZXsN9zM\nCsysYO3atbWPMjvbJ7vERH/7zjuwYYO/Dcf22jwnLw/+9z94992dt8+e7ZP3zJnl25s0gWuvhcsu\n88l9+3Zwzif+vLzavw8iIruosUVtZucCpzjnLi75/jdAL+fc76p6zh61qKHqboNwbY/0OfLzoV8/\nn6Sdg9tvh5tuqv37ICINTnUt6lAS9THAP4Ce+K6PSUCBc+6hqp6zx4m6PsjP910ezzwDq1fDwoVw\n2GFBRyUiMa5OXR/OuQ+AqcACYHHJc8aHNcL6JDMTbr4ZXn3V91X/+tf+oqOIyB4KaRy1c260c66j\nc66Lc+4C59yWSAcW9zp0gL//HebOhbFjg45GROKYZiZG0pAhkJsLd9yhC4sisseUqCPtoYfgiCNg\n6FBYty7oaEQkDilRR1qzZn5CzLp1foLNn/6k2YwiUiuhzkyUuujWzY+zfuAB32fdpIkmw4hIyNSi\njpYDDvC3O3b4STPqsxaREClRR8vxx/taIOCnqGdnBxqOiMQPJepoycz0I0DM4JVX1O0hIiFToo6m\nc87xU8uTkoKORETiiBJ1NPXs6W/nzQs2DhGJK0rU0dSqla9nrUQtIrWgRB1tGRlK1CJSK0rU0ZaR\nAStWwLffBh2JiMQJJepoy8jwtx9+GGwcIhI3lKijrVs3vzKMuj9EJERK1NG2117QubMStYiETIk6\nCKUXFENYWFhERIk6CBkZflHdL74IOhIRiQNK1EEovaCo7g8RCYESdRA6d4amTTXyQ0RCUmOiNrOj\nzKywwtd/zezqaARXbzVqBD16qEUtIiEJZRXyT51zac65NKAH8DPwUsQjq+8yMmDBAiguDjoSEYlx\nte366Ad84ZxbEYlgGpSMDNi8GZYsCToSEYlxtU3Ug4FnK3vAzIabWYGZFaxdu7bukdV3uqAoIiEK\nOVGbWWMgB3i+ssedc+Odc+nOufRWrVqFK776q107aNlSiVpEalSbFvWpwALnnKoJhYOZr0+tRC0i\nNahNoh5CFd0esocyMuDjj+HHH4OORERiWEiJ2sz2Ak4CXoxsOA1MRoafRr5gQdCRiEgMCylRO+d+\ncs61cM5tjHRADYqW5hKREGhmYpC0NJeIhECJOmhamktEaqBEHbSMDPj6ay3NJSJVUqIOWunEl2uv\nhfz8YGMRkZikRB20rVv97VNPQb9+StYishsl6qB98IG/dc4n7by8QMMRkdijRB207Gxf9hSgcWP/\nvYhIBUrUQcvMhJtv9vf/9jf/vYhIBUrUseDCC/2tppKLSCUaBR2AAIceCoccAnPmwBVXBB1Ng1Bc\nXMzKlSvZvHlz0KFIA5OcnEzbtm1JSkoK+TlK1LEiKwvee89fVDQLOpp6b+XKlTRv3px27dpher8l\nSpxzfP/996xcuZL27duH/Dx1fcSKrCxYtcpPfpGI27x5My1atFCSlqgyM1q0aFHrT3JK1LHiuOP8\n7ezZwcbRgChJSxD25PdOiTpWpKRA8+a+n1oahG+++YbBgwdz+OGH06NHDwYMGMBnn30WdFghmTRp\nEr///e+r3Wf16tUMGjQIgMLCQl577bWyx6ZPn86dd94Z8jkeffRRnnzyyVrHmZeXx9y5c8u+39Pj\nBE191LEiMdEPzVOLukFwznHWWWcxbNgwnnvuOQAWLlzIt99+y5FHHhlwdOHRpk0bpk6dCvhEXVBQ\nwIABAwDIyckhJycn5GONGDFij2LIy8ujWbNmHHvssXU6TtDUoo4lWVl+VfIffgg6EqlMfj6MGxeW\naf4zZ84kKSlpp8TRtWtXevfujXOOkSNH0qVLF1JSUpgyZQrgk07fvn0ZOHAgHTp04Prrr2fy5Mlk\nZGSQkpLCF198AUBubi6XXXYZvXr1okOHDuTl5XHRRRfRqVMncnNzy8737LPPkpKSQpcuXbjuuuvK\ntjdr1oybbrqJrl270qtXL76toWBYbm4uV155JcceeywdOnQoS85FRUV06dKFrVu3MmrUKKZMmUJa\nWhpTpkzZqbX8yiuvcMwxx9CtWzdOPPHESs83ZswY7rnnHlavXk1aWlrZV2JiIitWrKj0GEVFRTz6\n6KPcd999pKWl8d5775UdB/w/j169epGamspZZ53Fhg0bAMjOzua6664jIyODI488kvfee6+2P96w\nU4s6lhx3nB/1kZ8Pp54adDQNx9VXQ2Fh9fts3AiLFsGOHZCQAKmpsM8+Ve+flgb331/lw0uWLKFH\njx6VPvbiiy9SWFjIwoULWbduHT179qRPnz6Ab3UvXbqU/fffnw4dOvDb3/6WefPm8cADD/DQQw9x\nf8k5N2zYQH5+PtOnTycnJ4c5c+YwceJEevbsSWFhIQcccADXXXcd8+fPZ7/99qN///5MmzaNM888\nk59++olevXpxxx13cO211zJhwgRuLp2UVYU1a9Ywe/Zsli1bRk5OTlmXB0Djxo259dZbKSgo4K9/\n/SvguzVKHXfccbz//vuYGRMnTuSuu+7i3nvvrfQ8bdq0obDkZ/Xwww/z7rvvcthhh7H33ntXeowR\nI0bQrFkz/vjHPwIwY8aMsmP95je/4aGHHqJv376MGjWKsWPHlr1/27ZtY968ebz22muMHTuWt99+\nu9rXH2lK1LHkmGN8F8icOUrUsWbjRp+kwd9u3Fh9oq6D2bNnM2TIEBITEznwwAPp27cvH374IXvv\nvTc9e/akdevWABx++OH0798fgJSUFGbOnFl2jDPOOAMzIyUlhQMPPJCUlBQAOnfuTFFREStWrCA7\nO5tWrVoBMHToUGbNmsWZZ55J48aNOf300wHo0aMHb731Vo0xn3nmmSQkJHD00UfX2ALf1cqVKznv\nvPNYs2YNW7duDWnY2pw5c5gwYQKzS7oKa3uMjRs38sMPP9C3b18Ahg0bxrnnnlv2+Nlnnw34119U\nVFSr1xMJStSxZK+9oFs39VNHWzUt3zL5+b664datvibL5Ml1mu7fuXPnsi6C2mjSpEnZ/YSEhLLv\nExIS2LZt2277Vdyn4n7VTbZISkoqG5mQmJi403FDics5F+Kr8a644gquueYacnJyyMvLY8yYMdXu\nv2bNGi6++GKmT59Os2bN9ugYNSl9PaG+/kgLdXHbfc1sqpktM7OlZqaCFJGSleVXfCkuDjoSqSgz\nE2bMgNtu87d1rMlywgknsGXLFsaPH1+2bdGiRbz33nv07t2bKVOmsH37dtauXcusWbPIKK1bHiYZ\nGRm8++67rFu3ju3bt/Pss8+WtS4joXnz5vxYRYmEjRs3cvDBBwPwxBNPVHuc4uJizj33XP785z/v\ndNG1qmNUdd599tmH/fbbr6z/+amnnoro66+rUC8mPgC84ZzrCHQFlkYupAbuuONg0yb46KOgI5Fd\nZWbCDTeEpXCWmfHSSy/x9ttvc/jhh9O5c2duuOEGDjroIM466yxSU1Pp2rUrJ5xwAnfddRcHHXRQ\nGF5AudatW3PnnXdy/PHH07VrV3r06MHAgQPDeo6Kjj/+eD755JOyi4kVjRkzhnPPPZcePXrQsmXL\nao8zd+5cCgoKGD16dNkFxdWrV1d5jDPOOIOXXnqp7GJiRU888QQjR44kNTWVwsJCRo0aFb4XHGZW\n08cUM9sHKAQ6uBA/06Snp7uCgoIwhNcArVkDbdrAvffCNdcEHU29tXTpUjp16hR0GNJAVfb7Z2bz\nnXPple0fSou6PbAWeNzMPjKziWa21647mdlwMysws4K1a9fuSewC0Lo1dOigiS8iUiaURN0I6A48\n4pzrBvwEXL/rTs658c65dOdceumVZNlDWVn+gmItL8qISP0USqJeCax0zpWsGcVUfOKWSMnKgu++\ng5IJDCLSsNWYqJ1z3wD/MbOjSjb1Az6JaFQNnQo0iUgFoY76uAKYbGaLgDTgT5ELSejUCfbdV/3U\nIgKEOOHFOVcIVHo1UiIgIaG8n1pEGjwVZYpVWVmwbBmsWxd0JBIhpbPqQpWXl1c2tTsItY23okmT\nJrF69epKH8vNza1xluaelCutWIBp1KhRe1SvY9q0aXzySXlP754ep640hTxWlfZTz50LtSgHKRKL\nJk2aRJcuXWjTps0ePb+u5UpvvfXWPTrvtGnTOP300zn66KPrdJy6Uos6VqWn+wJN994blrKaUndh\nrHK6k7y8PLKzsxk0aBAdO3Zk6NChZfUy3njjDTp27Ej37t158cUXy57z008/cdFFF5GRkUG3bt14\n+eWXAZ8QBw4cSHZ2NkcccQRjx44te87TTz9NRkYGaWlpXHrppWzfvh2ouqzpV199RWZmJikpKbtV\nz7v77rvp2bMnqampjB49GvBlTTt16sQll1xC586d6d+/P5s2bWLq1KkUFBQwdOhQ0tLS2LRpU5Xv\nRbt27Rg9ejTdu3cnJSWFZcuW1ViudMKECfTs2ZOuXbtyzjnn8PPPP+923NJWe0FBQdmMxpSUlLKa\nJpUdY+7cuUyfPp2RI0eSlpbGF198sVPrf8aMGXTr1o2UlBQuuugitmzZUuVrqCsl6lhVWOjHUc+a\n5YsBKVlHzNVXQ3Z29V/duvkPOTfe6G+7dat+/6uvrl0MH330Effffz+ffPIJX375JXPmzGHz5s1c\ncsklvPLKK8yfP59vvvmmbP877riDE044gXnz5jFz5kxGjhzJTz/9BMC8efN44YUXWLRoEc8//zwF\nBQUsXbqUKVOmMGfOHAoLC0lMTGTy5MkAZWVNFy5cSJ8+fZgwYQIAV111FZdddhmLFy8uq9gH8Oab\nb7J8+XLmzZtHYWEh8+fPZ9asWQAsX76cyy+/nI8//ph9992XF154gUGDBpGens7kyZMpLCykadOm\n1b4XLVu2ZMGCBVx22WXcc889tGvXjhEjRvCHP/yBwsJCevfuvdP+Z599Nh9++CELFy6kU6dOPPbY\nY1UeOz09ncLCQgoLCznllFPKyp9Wdoxjjz2WnJwc7r77bgoLCzn88MPLjrN582Zyc3OZMmUKixcv\nZtu2bTzyyCNVvoa6UqKOVXl55RNetm7130tgKqtyGk4ZGRm0bduWhIQE0tLSKCoqYtmyZbRv354j\njjgCM+P8888v2//NN9/kzjvvJC0tjezsbDZv3szXJQsjn3TSSbRo0YKmTZty9tlnM3v2bGbMmMH8\n+fPp2bMnaWlpzJgxgy+//BJgt7KmpWU958yZw5AhQwC44IILdjr3m2++Sbdu3ejevTvLli1j+fLl\nALRv3560tLTdjlUbtS0xumTJEnr37k1KSgqTJ0/m448/rvE5U6ZMYcGCBWXLgdX2GJ9++int27cv\nKww1bNiwsn9We/IaaqI+6liVne3LaW7Z4rtAsrODjqjeCqDK6W4qlgkNpbSmc44XXniBo446aqft\nH3zwwW6Lp5oZzjmGDRvGuHHjdjtWdWVNK1uI1TnHDTfcwKWXXrrT9qKiot1eR3XdHFWpbYnR3Nxc\npk2bRteuXZk0aRJ5NTRqlixZwpgxY5g1axaJiYl7dIxwv4aaqEUdq0rLajZv7j9rhzMrSK2Fucpp\nSDp27EhRUVHZElvPPvts2WMnn3wyDz30UFlf9kcVqi2+9dZbrF+/nk2bNjFt2jSysrLo168fU6dO\n5bvvvgNg/fr1rFixotrzZ2Vlla3nWNpNUnruf/zjH/zvf/8DYNWqVWXHrUp1ZU5DUd3zf/zxR1q3\nbk1xcfFOcVbmhx9+YMiQITz55JNULHVR1TGqOu9RRx1FUVERn3/+ORD5MqlK1LEsKwuGDPH1qUsu\nVEhwwljlNCTJycmMHz+e0047je7du3PAAQeUPXbLLbdQXFxMamoqnTt35pZbbil7LCMjg3POOYfU\n1FTOOecc0tPTOfroo7n99tvp378/qampnHTSSaxZs6ba8z/wwAM8/PDDpKSksGrVqrLt/fv359e/\n/nXZhcZBgwbVmIRzc3MZMWJEjRcTq1JdudLbbruNY445hqysLDp27FjtcV5++WVWrFjBJZdcUnZR\nsbpjDB48mLvvvptu3bqV/cME/7N5/PHHOffcc0lJSSEhISGiC+fWWOZ0T6jMaRj9619w+unw+utw\nyilBR1Nv1Ncyp5MmTdppbUKJTZEocypB6tfPL9E1fXrQkYhIQJSoY11yMpx8sk/UKnsqNcjNzVVr\nuh5Soo4HOTmwahXMnx90JCISACXqeHDaab5Qk7o/wioS12dEarInv3dK1PGgZUs/RK9kmrDUXXJy\nMt9//72StUSVc47vv/+e5OTkWj1PE17iRU4O/PGP8NVX0L590NHEvbZt27Jy5Uq0vqdEW3JyMm3b\ntq3Vc5So48XAgT5RT58OV10VdDRxLykpifb6hydxQl0f8eKXv4Sjj1Y/tUgDpEQdTwYOhHffhQ0b\ngo5ERKIopERtZkVmttjMCs1MUw6DkpMD27fDa68FHYmIRFFtWtTHO+fSqpriKFGQkQEHHaTuD5EG\nRl0f8SQhAc44w9f9UJEmkQYj1ETtgDfNbL6ZDa9sBzMbbmYFZlagIU8RlJMDP/6ohQREGpBQE/Vx\nzrnuwKnA5WbWZ9cdnHPjnXPpzrn0inVeJcz69YMmTWD0aC3PJdJAhJSonXOrSm6/A14CMiIZlFSj\nsBC2bYMPPtBaiiINRI2J2sz2MrPmpfeB/sCSSAcmVai4luKWLeoCEWkAQpmZeCDwUsnaaY2AZ5xz\nb0Q0Kqladrbv+ti0Ccy0lqJIA1BjonbOfQl0jUIsEorSxfuuugoWLvSzFUWkXtPwvHiUmQl//atf\nErtk8VERqb+UqONVz56QkgKPPRZ0JCISYUrU8coMLr4YPvwQFi0KOhoRiSAl6nh2/vnQuLFa1SL1\nnBJ1PGvRAs48E55+WlPKReoxJep4d/HFsH49TJsWdCQiEiFK1PHuxBPhsMPU/SFSjylRx7uEBLjw\nQnj7bSgqCjoaEYkAJer64MIL/e3jjwcbh4hEhBJ1fXDooXDSST5Rb98edDQiEmZK1PXFxRfDf/7j\nu0BEpF4JpSiTxIOBA/1wvbvuggULfLGmzMygoxKRMFCiri+aNPH1qf/5T79SeePGvniTkrVI3FPX\nR33Spo2/3b7dF2xSrWqRekGJuj751a8gMdHfT0pSrWqRekKJuj7JzISpU6FRI+jdW90eIvWEEnV9\nc+aZcN118NZbMG9e0NGISBgoUddH110HBxwA//d/5esrikhk5efDuHERWXBaibo+at4cbr0VZs9W\nsSaRaMjP99eEbrrJj74Kc7IOOVGbWaKZfWRmr4Y1AomMiy/26ylee60fASIikfO3v/m/M+ciMuKq\nNi3qq4ClYT27RE6jRnD33fD55/Doo0FHI1J/vfYaPPusL5CWmOjnMIR5xFVIidrM2gKnARPDenaJ\nrFNP9R/Dxo6FDRuCjkak/nnzTTj7bEhLg9dfh9tui8hEs1BnJt4PXAs0r2oHMxsODAc49NBD6x6Z\n1J0Z3HMPdO8Ov/89dOmiqeUi4fLOO750Q8eOPmHvvz/07x+RU9WYqM3sdOA759x8M8uuaj/n3Hhg\nPEB6erqGGsSKtDTfsn7mGf/RrEkTTS0XqYv8fF+p8skn4YgjfCG0/feP6ClD6frIAnLMrAh4DjjB\nzJ6OaFQSXqmp/nbHDk0tF6mLOXPg+ONhwgT/t3TnndCyZcRPW2Oids7d4Jxr65xrBwwG3nHOnR/x\nyCR8cnL8BQ7wV6XVmpZ4UdXY5HBtD+U5//qXX0B66FDftVG6kHRCAixaVLfXFyJVz2sIMjN9K/q+\n++D55+HBB+G44/zIEJFoyc/3v4e7Xid5+2149VVISfH9vVu3+q9Fi+Dmm2HbNv+7euON8Mtfwmef\n+ZZscbHffuWVfvGM5cvh73/3+ycmQm4uHHwwfP01PPWUL1aWmAi/+Y1fZzQhwddwf/zx8uecfz60\nbu2fM2WK317qgAOgTx/fN719e0RGd1TFXARmrqWnp7uCgoKwH1fC4MEH4aqr/DjrCRP8BUeRSMvP\n9yOQtmzxCfHkk2HjRliyJPZGJDVq5D95lq6WZAa/+53/20lIqPofTh2Z2XznXHplj2lmYkNz5ZVw\nyy1+1fIbbgg6GmkItm3zC1ps2uSvkxQX+0TnHHToUN5YKF2oOS8P5s6Ff/zDX/xOTITkZD9W+dNP\nfc315OTy7a++Ct9/7+vbNG3qtzdt6mfm7tjhj1Vx+5w5PgkXF/va7RUfmzvXb3/vvfLtycm+2yOh\nJF1mZvq/nSh2IapF3RA5B5dfDo884m8PPljD9iQy/v1vX3Pm44/LE13FkUelLe2tWytf7KKq1mu4\ntu/pcyKguha1EnVDtX27//g5Y4Zv0SQna9iehEd+vm/1vv++/+rQwc+SPegg34INOCHGquoSta4m\nNVSJif4PY8YM38LetMl/hGzAfygSBvn50Lev7z4AuOIKn6SbNPHfH3vs7s/JzNTvXQ3UR92Q9evn\n++FK+wgfeQReeSXYmCS+PfpoeZJOTPQjKEqTtOwxtagbssxM36LOy4NDDvHTzXNy4Le/hfPOgw8/\nbPAfR6UWVq2Cl1/2//gTEqI6fK2+Ux+1lNuyBcaM8WNUzfyXppxLKLZvhxNP9KsKTZwIRUX6J19L\n6qOW0DRp4mdirV8P48eX912PHw+9emnMtVTt9tv9J7NJk2DIkKCjqXfURy27y80t77s28398aWkw\nebIfXxqh5YYkTr37rl9R6IILYNiwoKOpl9T1IZUrHTKVlQVffeUnLHzySXmrWsP5BGDdOujaFZo1\ng/nz/a3sEc1MlNornX3Vp49vJS1e7GskOFfeJTJ8uC+WXrEegjQcc+f6mjFr1/q6GErSEaM+aglN\nQgKMGOGLOm3d6lvWX38NAwZAmzb+Y2/XrrqI1FCULuZaXAxJSf4ft0SMErWEruJwvuxs6NHDT5J5\n/HE/qWHHDr9fUpIvqj54cJDRSiRNn14+XnrHDv87oX/OEaM+agmPG2/0w/oq/j516QKDBvnSlCtW\n+ILr+mOuHwYNghdeKF/MVdcr6kzD8yTyzjgD7r/fd4skJflukgUL/LjsUo0awV//6ifUJCYGFqrU\n0ddf+xmsAwfCMceoqysK1KKW8KmsuE5lLe1WrXxiP+oo2LwZTjpJf+jx5NJL/ZDNzz/3M1olLFQ9\nT4KzaxnLG26ApUv9VOOff/b7JCTAyJF+QYPWrYONV6r35Zf+H+yIEfDQQ0FHU68oUUuwKmtp3347\njB5dfgGyVHq6Hz2SnAy//nXl1dYkOBdd5Av4f/GFH+0jYVOnRG1mycAsoAm+T3uqc250dc9RopYa\n7drSHj/er1/3zDN+eaZSp5/uZ0qedJIvPq+6xcFZvhw6dfKrBP3lL0FHU+/U9WLiFuAE59z/zCwJ\nmG1mrzvn3g9rlNKw7DrUr2LiveUWX+THzC+v9Oqr/uJj6WSb0kJRam1H1623+vf+uuuCjqTBqTFR\nO9/k/l/Jt0klX+HvL5GGp7KC8dnZvoVd2tL+97/99ltu8TUlwF+AHDAAfvUrOOUUX7VNre3IWrrU\n13oZORIOPDDoaBqckPqoze+tj5AAAAptSURBVCwRmA/8EnjYObfbv1QzGw4MBzj00EN7rFixIsyh\nSoNRWZ92xa6ShATfmv7oI/jvf3dubZeO6c3KCvIV1D/nnQevvebrvrRsGXQ09VLYLiaa2b7AS8AV\nzrklVe2nPmqJiF0TeHGx3zZqVHlrG+AXv/BjfPv3h/33961ttbT33OLFkJoKN93kLwJLRIRtwotz\n7gczmwmcAlSZqEUiYteukqQkXzRq3Ljy1nZiot/2zjt+dEKpRo38BcvcXNXVrq3f/973TffuHXQk\nDVaN1fPMrFVJSxozawqcBCyLdGAiISu9MHnbbb7F/frrsHq1X1i1NClv2+aHlh1yCPzud3DffX5/\n1dWu3t/+BrNm+X+CZ52l9ysgoQzPSwWeABLxif2fzrlbq3uOuj4kJlTs105Kgj/+0XeDvPaaX3YM\nfH/3tdf6pK5xwTv7+Wf/j239ev99YqL/53bDDcHGVU9pwos0XJVdmLztNl+DZNfJNt27+8k2TZvC\n0KEa/nfNNf6TR5Mm/hOJii9FlBK1SEW7Trb5+99h5Urfp714sd/HDM4/37fCU1IaXr926aIAl17q\nF4zQ0MeIU6IW2VVlLe1x48on24BPzs752XhDhsCRR/paF/U9YW3aBN26+dslS6B586AjahBU5lRk\nV6FMtnn+eV/S87nn/BDAUklJvsznySdHNeSoGTsWPv3UTzZSko4JalGLVFRZSxvg+uv9Ar+lfy+J\niXD22X49yb33htmz60dL+8MPoVcvuPBCmDgx6GgaFHV9iNRVxX7tRo18Pe2ZM+H77/3jZv6i2zvv\nxG+y3rLFL6+2YYMfHbPvvkFH1KBoFXKRuqo4VnvmTN8tsnq1v+AIvqW9ebOfUDN9uh8lkZ/v+73j\nYexxfj6ceqpP0OPHK0nHGPVRi4Rq137txo395JkXXihfmX39ej99vVUr3zKtWH8kVlva+fl+Pcst\nW3yXzv77Bx2R7EItapG6qNjSnjXLt7JffBH22ce3qrdv96MnHnzQt7hjjXPwpz+VTwAC30cvMUV9\n1CKRkJ8PJ5xQngCd88l78GDfD7x2bfCrsm/ZApdfDo895mdomsV+678e0/A8kWjLzPQXFvPyfJGo\nzZv9grCPP+4n2IC/KHnffX5SSVJSdOP75hs/aiU/H26+2df1njWrfoxcqYfUohaJptGjfTdJxb+7\nffbxifKoo/y09gEDIpcs8/Ph6afhn//0tTwmTYJzz43MuaRWNDxPJFbsOn191Ci/FuFLL/mLj+C7\nIHJyfIs3Kws6dID336/bNO4tW/xojmuu8X3nZr51P2xYOF+d1IG6PkRiRVVrRR5+uJ++vmOHb22/\n8Qa8/LJ/bL/9YONGv71RI7j7bjjtNDj0UJg/v/IEPneuH43iHHz2mR9S+PPP5Y8nJPgLnxIX1KIW\niQW7trTfest3icyZ4/u0P/po9+eUFopyzt/ff39/+/PPOyflgw/2QwYPO8xXDSw9hy4axhS1qEVi\nXVUt7S5d/DJYFetq33uvX27sySd9S7lU+/bQsycsXOgTv3N+XPTll5fXkO7dW5Xw4pBa1CLxoKYF\nfyu2kKvaLjFNFxNF6quqikhVtV1ilhK1iEiMU1EmEZE4Fsoq5IeY2Uwz+8TMPjazq6IRmIiIeKGM\n+tgG/J9zboGZNQfmm9lbzrlPIhybiIgQQovaObfGObeg5P6PwFLg4EgHJiIiXq36qM2sHdAN+KCS\nx4abWYGZFaxduzY80YmISOiJ2syaAS8AVzvn/rvr48658c65dOdceqtWrcIZo4hIgxbS8DwzSwJe\nBf7tnPtLCPuvBVbsYUwtgXV7+Nxoi6dYIb7ijadYIb7ijadYIb7irUushznnKm3l1piozcyAJ4D1\nzrmr9zCAkJlZQVVjCWNNPMUK8RVvPMUK8RVvPMUK8RVvpGINpesjC7gAOMHMCku+BoQ7EBERqVyN\nw/Occ7MBi0IsIiJSiVicmTg+6ABqIZ5ihfiKN55ihfiKN55ihfiKNyKxRqTWh4iIhE8stqhFRKQC\nJWoRkRgXeKI2s/3N7C0zW15yu18l+6SZWX5JUahFZnZelGM8xcw+NbPPzez6Sh5vYmZTSh7/oGQG\nZyBCiPWakgJbi8xshpkdFkScFeKpNt4K+51jZs7MAhumFUqsZvarCgXMnol2jLvEUtPvwqElBdc+\nKvl9CGw0l5n9w8y+M7MlVTxuZvZgyWtZZGbdox1jhVhqinVoSYyLzWyumXWt80mdc4F+AXcB15fc\nvx74cyX7HAkcUXK/DbAG2DdK8SUCXwAdgMbAQuDoXfb5HfBoyf3BwJSA3stQYj0e+EXJ/cuCijXU\neEv2aw7MAt4H0mM1VuAI4CNgv5LvD4jl9xZ/4euykvtHA0UBxtsH6A4sqeLxAcDr+BFovYAPYjjW\nYyv8DpwajlgDb1EDA/ETaii5PXPXHZxznznnlpfcXw18B0RrnnoG8Llz7kvn3FbgOXzMFVV8DVOB\nfiUThaKtxlidczOdc6Urn74PtI1yjBWF8t4C3Ab8GdgczeB2EUqslwAPO+c2ADjnvotyjBWFEq8D\n9i65vw8Q2LLkzrlZwPpqdhkIPOm894F9zax1dKLbWU2xOufmlv4OEKa/sVhI1Ac659aU3P8GOLC6\nnc0sA99C+CLSgZU4GPhPhe9Xsnv1wLJ9nHPbgI1Ai6hEV0UcJSqLtaKL8a2UoNQYb8lH3EOcc/+K\nZmCVCOW9PRI40szmmNn7ZnZK1KLbXSjxjgHON7OVwGvAFdEJbY/U9nc7VoTlbywqq5Cb2dvAQZU8\ndFPFb5xzzsyqHC9Y8h/0KWCYc25HeKNsWMzsfCAd6Bt0LFUxswTgL0BuwKGEqhG++yMb34qaZWYp\nzrkfAo2qakOASc65e80sE3jKzLrobys8zOx4fKI+rq7Hikqids6dWNVjZvatmbV2zq0pScSVflw0\ns72BfwE3lXz0iZZVwCEVvm9bsq2yfVaaWSP8x8jvoxNepXGUqixWzOxE/D/Jvs65LVGKrTI1xdsc\n6ALklfQkHQRMN7Mc51y0F+UM5b1die+PLAa+MrPP8In7w+iEuJNQ4r0YOAXAOZdvZsn4okJBdtlU\nJaTf7VhhZqnAROBU51ydc0EsdH1MB4aV3B8GvLzrDmbWGHgJ30c1NYqxgf8jO8LM2pfEMRgfc0UV\nX8Mg4B1XciUhymqM1cy6AX8HcgLuQ4Ua4nXObXTOtXTOtXPOtcP39wWRpGuMtcQ0fGsaM2uJ7wr5\nMppBVhBKvF8D/QDMrBOQDMRqMfnpwG9KRn/0AjZW6DKNKWZ2KPAicIFz7rOwHDSoK6cVrpC2AGYA\ny4G3gf1LtqcDE0vunw8UA4UVvtKiGOMA4DN8v/hNJdtuxScN8L/gzwOfA/OADgG+nzXF+jbwbYX3\ncXrAP/9q491l3zwCGvUR4ntr+K6aT4DFwOBYfm/xIz3m4EeEFAL9A4z1WfxormL8J5OLgRHAiArv\n7cMlr2VxwL8HNcU6EdhQ4W+soK7n1BRyEZEYFwtdHyIiUg0lahGRGKdELSIS45SoRURinBK1iEiM\nU6IWEYlxStQiIjHu/wGxgjpewbqOJgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TM2P1rbY0vM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "6eb94119-b295-495b-ae1e-d3516debdafc"
      },
      "source": [
        "def main():\n",
        "    # Create Server and Update\n",
        "    server = Server(clients)\n",
        "    server.update()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROUND 1 / 25 NUM SAMPLES : 29\n",
            "ROUND 1 / 25 UPDATE ACCURACY : 71.72 %\n",
            "ROUND 2 / 25 NUM SAMPLES : 94\n",
            "ROUND 2 / 25 UPDATE ACCURACY : 90.36 %\n",
            "ROUND 3 / 25 NUM SAMPLES : 94\n",
            "ROUND 3 / 25 UPDATE ACCURACY : 93.89 %\n",
            "ROUND 4 / 25 NUM SAMPLES : 100\n",
            "ROUND 4 / 25 UPDATE ACCURACY : 95.89 %\n",
            "ROUND 5 / 25 NUM SAMPLES : 59\n",
            "ROUND 5 / 25 UPDATE ACCURACY : 96.86 %\n",
            "ROUND 6 / 25 NUM SAMPLES : 100\n",
            "ROUND 6 / 25 UPDATE ACCURACY : 96.88 %\n",
            "ROUND 7 / 25 NUM SAMPLES : 51\n",
            "ROUND 7 / 25 UPDATE ACCURACY : 97.78 %\n",
            "ROUND 8 / 25 NUM SAMPLES : 75\n",
            "ROUND 8 / 25 UPDATE ACCURACY : 97.81 %\n",
            "ROUND 9 / 25 NUM SAMPLES : 60\n",
            "ROUND 9 / 25 UPDATE ACCURACY : 97.82 %\n",
            "ROUND 10 / 25 NUM SAMPLES : 95\n",
            "ROUND 10 / 25 UPDATE ACCURACY : 97.82 %\n",
            "ROUND 11 / 25 NUM SAMPLES : 56\n",
            "ROUND 11 / 25 UPDATE ACCURACY : 97.80 %\n",
            "ROUND 12 / 25 NUM SAMPLES : 100\n",
            "ROUND 12 / 25 UPDATE ACCURACY : 97.80 %\n",
            "ROUND 13 / 25 NUM SAMPLES : 4\n",
            "ROUND 13 / 25 UPDATE ACCURACY : 97.80 %\n",
            "ROUND 14 / 25 NUM SAMPLES : 24\n",
            "ROUND 14 / 25 UPDATE ACCURACY : 97.82 %\n",
            "ROUND 15 / 25 NUM SAMPLES : 60\n",
            "ROUND 15 / 25 UPDATE ACCURACY : 97.81 %\n",
            "ROUND 16 / 25 NUM SAMPLES : 88\n",
            "ROUND 16 / 25 UPDATE ACCURACY : 97.80 %\n",
            "ROUND 17 / 25 NUM SAMPLES : 84\n",
            "ROUND 17 / 25 UPDATE ACCURACY : 97.81 %\n",
            "ROUND 18 / 25 NUM SAMPLES : 36\n",
            "ROUND 18 / 25 UPDATE ACCURACY : 97.80 %\n",
            "ROUND 19 / 25 NUM SAMPLES : 82\n",
            "ROUND 19 / 25 UPDATE ACCURACY : 97.79 %\n",
            "ROUND 20 / 25 NUM SAMPLES : 50\n",
            "ROUND 20 / 25 UPDATE ACCURACY : 97.79 %\n",
            "ROUND 21 / 25 NUM SAMPLES : 96\n",
            "ROUND 21 / 25 UPDATE ACCURACY : 97.79 %\n",
            "ROUND 22 / 25 NUM SAMPLES : 73\n",
            "ROUND 22 / 25 UPDATE ACCURACY : 97.79 %\n",
            "ROUND 23 / 25 NUM SAMPLES : 29\n",
            "ROUND 23 / 25 UPDATE ACCURACY : 97.78 %\n",
            "ROUND 24 / 25 NUM SAMPLES : 54\n",
            "ROUND 24 / 25 UPDATE ACCURACY : 97.80 %\n",
            "ROUND 25 / 25 NUM SAMPLES : 59\n",
            "ROUND 25 / 25 UPDATE ACCURACY : 97.78 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}